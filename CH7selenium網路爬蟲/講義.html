
一、 網路爬蟲(web crawler)前置概念
網路爬蟲技術可以透過 url(uniform resource locator)訪問網站，並解析其HTML得到我們想要的資訊。
透過python自動執行一定步驟，可自動化的撈取資訊。
在講解網路爬蟲之前，還需要知道的基礎知識:
1. HTML（Hypertext Markup Language），中文全名為「超文字標示語言」，是一種用來組織架構並呈現網頁內容的程式語言。
網頁內容的組成，可能包含了段落、清單、圖片或表格...等。簡單來說就是一種"用來描述網站顯示的內容是什麼的語言，也就是瀏覽器看得懂的語言"。
我們看見的網頁通常就是由一個個HTML檔案組成的。
2. 網路地址url(uniform resource locator)
在瀏覽器輸入的網址，將會透過網路伺服器(屬於網頁後端知識，有需要再了解)，獲取對應的HTML網頁，並回傳給瀏覽器顯示給使用者看。
3.HTTP、HTTPS (知道一下概念就好，有想當駭客的話再深入)
HTTP( Hyper Text Transfer protocol)，超本文傳輸協定，是一種國際規範的網路通訊協定，
簡單粗暴的白話文說明就是，規定瀏覽器想獲得資訊，該使用怎樣的格式來請求資訊

二、網路爬蟲(web crawler)

1. 表頭(headers):是描述客戶端(client)向伺服器端(server)發出請求時所使用的協議、編碼、以及傳送內容的長度。
有的網站沒有反爬蟲機制，python程式就可以針對網頁自由的獲取資訊，然而有些網頁會有反爬蟲機制
，該網站的伺服器會針對客戶請求的表頭(headers)做檢查，以此判斷是不是由瀏覽器給予的請求，可能會阻擋非瀏覽器的請求。
若想避免被阻擋，可以將header 加入 use_agent，用於將程式偽裝成瀏覽器，以避免大部分的反爬蟲機制。

2.selenium 網路爬蟲工具，一個專門用來模仿網頁瀏覽器操作的模組。

 2.1 安裝模組: pip install selenium
 2.2 安裝驅動: https://chromedriver.chromium.org/downloads
 注意安裝版本需與瀏覽器一致，下載之後解壓縮，將會得到chromedriver檔案
 之後將這個檔案的路徑作為參數即可驅動，後續會詳細說明

 2.3 如何利用html 元素 web element，提取想要解析的網頁區塊(Xpath):
 HTML通常會有id、class、name等屬性，細節屬於HTML語法的部分，此處不細究。
 但是網頁作者如果沒有使用這樣的結構，我們此處使用Xpath的方式解決這個問題，利用Xpath可以絕對路徑或相對路徑提取網頁的指定區塊
 所謂Xpath的方式，就是以browser物件提供的方法find_element_by_xpath()實現指定網頁區塊的方法，
 請先打開test.html及其對應的結構圖test_html_structure.png說明範例
 Example:
    1. 絕對路徑(少用):
        例如，想指定<h4>區塊，可以絕對路徑指定:
        /html/body/section/h4
    2. 相對路徑(常用):
        例如，想指定<h4>區塊，可以相對路徑指定:
            a. //h4
            b. //body/section/h4
            c. //section/h4
            d. //body/*/*/h4
    3. 實際操作請看程式碼web_crawler.py
 2.4 補充說明-chrome外掛ChroPath:可方便取得網頁元素的Xpath
    1. 請google搜尋"ChroPath for chrome"將此擴充功能加置瀏覽器

 三、 HTML詳細解析與BeautifulSoup(需另外課程說明)
    1. 網頁前端組成的三大語言
    html:網頁骨架
    css:網頁美觀與排版
    JavaScript: 網頁功能(動作)
    2.HTML教程






